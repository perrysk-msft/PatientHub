{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.  \n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Azure Machine Learning Pipelines for batch prediction\n",
    "\n",
    "In this notebook we will demonstrate how to run a batch scoring job using Azure Machine Learning pipelines. Our example job will be to take an already-trained image classification model, and run that model on some unlabeled images. The image classification model that we'll use is the __[Inception-V3 model](https://arxiv.org/abs/1512.00567)__  and we'll run this model on unlabeled images from the __[ImageNet](http://image-net.org/)__ dataset. \n",
    "\n",
    "The outline of this notebook is as follows:\n",
    "\n",
    "- Register the pretrained inception model into the model registry. \n",
    "- Store the dataset images in a blob container.\n",
    "- Use the registered model to do batch scoring on the images in the data blob container."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "Make sure you go through the configuration Notebook located at https://github.com/Azure/MachineLearningNotebooks first if you haven't. This sets you up with a working config file that has information on your workspace, subscription id, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "from azureml.core.datastore import Datastore\n",
    "from azureml.core.runconfig import CondaDependencies, RunConfiguration\n",
    "from azureml.data.data_reference import DataReference\n",
    "from azureml.pipeline.core import Pipeline, PipelineData\n",
    "from azureml.pipeline.steps import PythonScriptStep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Falling back to use azure cli login credentials.\n",
      "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
      "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: F:\\PatientHub\\MLModels\\DiabetesReadmission\\aml_config\\config.json\n",
      "Workspace name: xiaoyzhu-MLworkspace\n",
      "Azure region: westus2\n",
      "Subscription id: a6c2a7cc-d67e-4a1a-b765-983f08c0423a\n",
      "Resource group: xiaoyzhu-mlworkspace\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up machine learning resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up datastores\n",
    "First, letâ€™s access the datastore that has the model, labels, and images. \n",
    "\n",
    "### Create a datastore that points to a blob container containing sample images\n",
    "\n",
    "We have created a public blob container `sampledata` on an account named `pipelinedata`, containing images from the ImageNet evaluation set. In the next step, we create a datastore with the name `images_datastore`, which points to this container. In the call to `register_azure_blob_container` below, setting the `overwrite` flag to `True` overwrites any datastore that was created previously with that name. \n",
    "\n",
    "This step can be changed to point to your blob container by providing your own `datastore_name`, `container_name`, and `account_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_name = \"xiaoyzhustoragepdnwlbjz\"\n",
    "datastore_name=\"patienthubdatastore\"\n",
    "container_name=\"diabetes\"\n",
    "\n",
    "def_data_store = ws.get_default_datastore() \n",
    "# Get blob storage associated with the workspace\n",
    "def_blob_store = Datastore(ws, \"workspaceblobstore\")\n",
    "\n",
    "# batchscore_blob = Datastore.register_azure_blob_container(ws, \n",
    "#                       datastore_name=datastore_name, \n",
    "#                       container_name= container_name, \n",
    "#                       account_name=account_name, \n",
    "#                       create_if_not_exists=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, letâ€™s specify the default datastore for the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_data_store = batchscore_blob = ws.get_default_datastore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading F:\\PatientHub\\MLModels\\DiabetesReadmission\\data\\shap_values.csv\n",
      "Uploaded F:\\PatientHub\\MLModels\\DiabetesReadmission\\data\\shap_values.csv, 1 files out of an estimated total of 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_1b79e64515844a5ba73dd115adda9269"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def_blob_store.upload_files(\n",
    "    [r'F:\\PatientHub\\MLModels\\DiabetesReadmission\\data\\shap_values.csv'],\n",
    "    target_path=\"shap_values\", \n",
    "    overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure data references\n",
    "Now you need to add references to the data, as inputs to the appropriate pipeline steps in your pipeline. A data source in a pipeline is represented by a DataReference object. The DataReference object points to data that lives in, or is accessible from, a datastore. We need DataReference objects corresponding to the following: the directory containing the input images, the directory in which the pretrained model is stored, the directory containing the labels, and the output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_input_data = DataReference(\n",
    "    datastore=def_blob_store,\n",
    "    data_reference_name=\"shap_values\",\n",
    "    path_on_datastore=\"shap_values/shap_values.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_shap_values"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob_input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and attach Compute targets\n",
    "Use the below code to create and attach Compute targets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found compute target. just use it. cpu-PatientHub\n"
     ]
    }
   ],
   "source": [
    "# choose a name for your cluster\n",
    "aml_compute_name = os.environ.get(\"AML_COMPUTE_NAME\", \"cpu-PatientHub\")\n",
    "cluster_min_nodes = os.environ.get(\"AML_COMPUTE_MIN_NODES\", 0)\n",
    "cluster_max_nodes = os.environ.get(\"AML_COMPUTE_MAX_NODES\", 1)\n",
    "vm_size = os.environ.get(\"AML_COMPUTE_SKU\", \"Standard_DS4_v2\")\n",
    "\n",
    "\n",
    "if aml_compute_name in ws.compute_targets:\n",
    "    # compute_target.delete()\n",
    "    compute_target = ws.compute_targets[aml_compute_name]\n",
    "    if compute_target and type(compute_target) is AmlCompute:\n",
    "        print('found compute target. just use it. ' + aml_compute_name)\n",
    "else:\n",
    "    print('creating a new compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = vm_size, # NC6 is GPU-enabled\n",
    "                                                                vm_priority = 'lowpriority', # optional\n",
    "                                                                min_nodes = cluster_min_nodes, \n",
    "                                                                max_nodes = cluster_max_nodes)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, aml_compute_name, provisioning_config)\n",
    "    \n",
    "    # can poll for a minimum number of nodes and for a specific timeout. \n",
    "    # if no min node count is provided it will use the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    \n",
    "     # For a more detailed view of current Azure Machine Learning Compute  status, use get_status()\n",
    "    print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the Model\n",
    "\n",
    "Download and extract the model from http://download.tensorflow.org/models/inception_v3_2016_08_28.tar.gz to `\"models\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register the model with Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model DiabetesReadmission\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from azureml.core.model import Model\n",
    "\n",
    "# register downloaded model \n",
    "model = Model.register(model_path = r'F:\\PatientHub\\MLModels\\DiabetesReadmission\\data\\model.pkl',\n",
    "                       model_name = \"DiabetesReadmission\", # this is the name the model is registered as\n",
    "                       tags = {'pretrained': \"DiabetesReadmission\"},\n",
    "                       description = \"Diabetes Readmission\",\n",
    "                       workspace = ws)\n",
    "# remove the downloaded dir after registration if you wish\n",
    "# shutil.rmtree(\"models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write your scoring script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do the scoring, we use a batch scoring script `batch_scoring.py`, which is located in the same directory that this notebook is in. You can take a look at this script to see how you might modify it for your custom batch scoring task.\n",
    "\n",
    "The python script `batch_scoring.py` takes input images, applies the image classification model to these images, and outputs a classification result to a results file.\n",
    "\n",
    "The script `batch_scoring.py` takes the following parameters:\n",
    "\n",
    "- `--model_name`: the name of the model being used, which is expected to be in the `model_dir` directory\n",
    "- `--label_dir` : the directory holding the `labels.txt` file \n",
    "- `--dataset_path`: the directory containing the input images\n",
    "- `--output_dir` : the script will run the model on the data and output a `results-label.txt` to this directory\n",
    "- `--batch_size` : the batch size used in running the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and run the batch scoring pipeline\n",
    "You have everything you need to build the pipeline. Letâ€™s put all these together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Specify the environment to run the script\n",
    "Specify the conda dependencies for your script. You will need this object when you create the pipeline step later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\n",
    "\n",
    "cd = CondaDependencies.create(conda_packages=[\"pyodbc\"], pip_packages=[\"azureml-defaults\", \"sqlalchemy\", \"pandas\",\"xgboost\"])\n",
    "cd.save_to_file(\".\",\"conda.yml\")\n",
    "\n",
    "# Runconfig\n",
    "amlcompute_run_config = RunConfiguration(conda_dependencies=cd)\n",
    "amlcompute_run_config.environment.docker.enabled = True\n",
    "amlcompute_run_config.environment.docker.gpu_support = False\n",
    "amlcompute_run_config.environment.docker.base_image = DEFAULT_CPU_IMAGE\n",
    "amlcompute_run_config.environment.spark.precache_packages = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify the parameters for your pipeline\n",
    "A subset of the parameters to the python script can be given as input when we re-run a `PublishedPipeline`. In the current example, we define `batch_size` taken by the script as such parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core.graph import PipelineParameter\n",
    "batch_size_param = PipelineParameter(name=\"param_batch_size\", default_value=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the pipeline step\n",
    "Create the pipeline step using the script, environment configuration, and parameters. Specify the compute target you already attached to your workspace as the target of execution of the script. We will use PythonScriptStep to create the pipeline step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_score_step = PythonScriptStep(\n",
    "    name=\"patienthub_batch_scoring\",\n",
    "    script_name=\"batch_scoring.py\",\n",
    "    arguments=[\"--model_name\", \"DiabetesReadmission\", \"--input_csv\", blob_input_data],\n",
    "    compute_target=compute_target,\n",
    "    inputs=[blob_input_data],\n",
    "    runconfig=amlcompute_run_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the pipeline\n",
    "At this point you can run the pipeline and examine the output it produced. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step patienthub_batch_scoring [cd281ffa][a5eba4d5-bd3e-45a0-a793-48c6fdfb3eab], (This step is eligible to reuse a previous run's output)\n",
      "Using data reference shap_values for StepId [dd716e1d][65b1920e-b523-4aef-a68b-52a53218e8ec], (Consumers of this data are eligible to reuse prior runs.)\n",
      "Submitted pipeline run: d9ca624e-e5b1-40df-ad54-ca9c0e255664\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(workspace=ws, steps=[batch_score_step])\n",
    "pipeline_run = Experiment(ws, 'batch_scoring').submit(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor the run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0efc4197e9cc413eb3ac7ce2ac8429cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': True, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(pipeline_run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: d9ca624e-e5b1-40df-ad54-ca9c0e255664\n",
      "Link to Portal: https://mlworkspace.azure.ai/portal/subscriptions/a6c2a7cc-d67e-4a1a-b765-983f08c0423a/resourceGroups/xiaoyzhu-mlworkspace/providers/Microsoft.MachineLearningServices/workspaces/xiaoyzhu-MLworkspace/experiments/batch_scoring/runs/d9ca624e-e5b1-40df-ad54-ca9c0e255664\n",
      "Status: Running\n",
      ".......................................................................................................................................................................\n",
      "Status: Finished\n",
      "{'runId': 'd9ca624e-e5b1-40df-ad54-ca9c0e255664', 'status': 'Completed', 'startTimeUtc': '2019-02-25T19:04:35.396224Z', 'endTimeUtc': '2019-02-25T19:19:22.100802Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': None, 'runType': 'HTTP', 'azureml.parameters': '{}'}, 'logFiles': {}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish a pipeline and rerun using a REST call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a published pipeline\n",
    "Once you are satisfied with the outcome of the run, you can publish the pipeline to run it with different input values later. When you publish a pipeline, you will get a REST endpoint that accepts invoking of the pipeline with the set of parameters you have already incorporated above using PipelineParameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "published_pipeline = pipeline_run.publish_pipeline(\n",
    "    name=\"patienthub_batch_scoring_pipeline\", description=\"Batch scoring for patientHub\", version=\"1.0\")\n",
    "\n",
    "published_id = published_pipeline.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rerun the pipeline using the REST endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get AAD token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.authentication import AzureCliAuthentication\n",
    "import requests\n",
    "\n",
    "cli_auth = AzureCliAuthentication()\n",
    "aad_token = cli_auth.get_authentication_header()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Authorization': 'Bearer eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsIng1dCI6Ik4tbEMwbi05REFMcXdodUhZbkhRNjNHZUNYYyIsImtpZCI6Ik4tbEMwbi05REFMcXdodUhZbkhRNjNHZUNYYyJ9.eyJhdWQiOiJodHRwczovL21hbmFnZW1lbnQuY29yZS53aW5kb3dzLm5ldC8iLCJpc3MiOiJodHRwczovL3N0cy53aW5kb3dzLm5ldC83MmY5ODhiZi04NmYxLTQxYWYtOTFhYi0yZDdjZDAxMWRiNDcvIiwiaWF0IjoxNTUzMDI2OTAyLCJuYmYiOjE1NTMwMjY5MDIsImV4cCI6MTU1MzAzMDgwMiwiX2NsYWltX25hbWVzIjp7Imdyb3VwcyI6InNyYzEifSwiX2NsYWltX3NvdXJjZXMiOnsic3JjMSI6eyJlbmRwb2ludCI6Imh0dHBzOi8vZ3JhcGgud2luZG93cy5uZXQvNzJmOTg4YmYtODZmMS00MWFmLTkxYWItMmQ3Y2QwMTFkYjQ3L3VzZXJzLzQ4NDA4ZWUxLTk4NGItNGUyNi1hZWM2LTcxMjU4ZWUzNTcyNS9nZXRNZW1iZXJPYmplY3RzIn19LCJhY3IiOiIxIiwiYWlvIjoiQVVRQXUvOEtBQUFBczNUWU9wWG81TlB2YjZicHNrY1gxVGVtakxCb1ByQm5KUWowUnIyZ2xUak4yT0pYYkZkaFVpVno2eklxcEZXOWxDRk96VGhyenY4TkRGUFREUEk1ZUE9PSIsImFtciI6WyJwd2QiLCJyc2EiLCJtZmEiXSwiYXBwaWQiOiIwNGIwNzc5NS04ZGRiLTQ2MWEtYmJlZS0wMmY5ZTFiZjdiNDYiLCJhcHBpZGFjciI6IjAiLCJkZXZpY2VpZCI6IjE5Yjk5ODlkLWVmY2EtNDYxYS05ZWUxLTZmMDRlMGUyNGEzMiIsImZhbWlseV9uYW1lIjoiWmh1IiwiZ2l2ZW5fbmFtZSI6IlhpYW95b25nIiwiaXBhZGRyIjoiMTMxLjEwNy4xNzQuMTY0IiwibmFtZSI6IlhpYW95b25nIFpodSIsIm9pZCI6IjQ4NDA4ZWUxLTk4NGItNGUyNi1hZWM2LTcxMjU4ZWUzNTcyNSIsIm9ucHJlbV9zaWQiOiJTLTEtNS0yMS0yMTI3NTIxMTg0LTE2MDQwMTI5MjAtMTg4NzkyNzUyNy0yNDQ1MDM1NCIsInB1aWQiOiIxMDAzMDAwMDg2MjUyMEE2Iiwic2NwIjoidXNlcl9pbXBlcnNvbmF0aW9uIiwic3ViIjoiRmIyV3BNOEpVTVdPVzVFWWVpb1FBOXBXNGl0NE1SaFpRMmFKS0xtRE9HdyIsInRpZCI6IjcyZjk4OGJmLTg2ZjEtNDFhZi05MWFiLTJkN2NkMDExZGI0NyIsInVuaXF1ZV9uYW1lIjoieGlhb3l6aHVAbWljcm9zb2Z0LmNvbSIsInVwbiI6InhpYW95emh1QG1pY3Jvc29mdC5jb20iLCJ1dGkiOiJJWDFaWHBQYW5FV1ZfRXo2TDZnREFBIiwidmVyIjoiMS4wIn0.f2jmS-inxahG9ny-cYBVT1Vv282J0pWA8MyKaFjl-Lcg3A6IMU1FPvdIH-DwkOD_Otbgnfb9uIeRdbz0-w2k2zKquBkFNZieLzuDYGJyC87Rm7JoSm_ArJT17ZUVNyO76IX2djZGjk2jNhC1OX1QN7G8H2TbMP-8SXr59voV6iYAygaOsR6Q1BVQlMqKnjHaZYRCwn3WlOquT1FF_Nf8Kaq1wSelRiSyZbsrv3Z-AdiNiPoz-UsvjeanLNLbnp2kHUxD50JxlGNZ9stoyefF_hSicMrKQa9WWrilq0jiOQUR-zGOi-2Cv7B4dMLB6MLlR6IPtHHcJHh-_g9aG_x2GQ'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aad_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run published pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rest_endpoint = published_pipeline.endpoint\n",
    "\n",
    "rest_endpoint = \"https://westus2.aether.ms/api/v1.0/subscriptions/a6c2a7cc-d67e-4a1a-b765-983f08c0423a/resourceGroups/xiaoyzhu-mlworkspace/providers/Microsoft.MachineLearningServices/workspaces/xiaoyzhu-MLworkspace/PipelineRuns/PipelineSubmit/565c32df-250c-461c-b9b7-2283cbaf55ab\"\n",
    "# specify batch size when running the pipeline\n",
    "response = requests.post(rest_endpoint, \n",
    "                         headers=aad_token, \n",
    "                         json={\"ExperimentName\": \"patienthub_batch_scoring\",\n",
    "                               \"ParameterAssignments\": {\"param_batch_size\": 50}})\n",
    "run_id = response.json()[\"Id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Authorization': 'Bearer eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsIng1dCI6Ik4tbEMwbi05REFMcXdodUhZbkhRNjNHZUNYYyIsImtpZCI6Ik4tbEMwbi05REFMcXdodUhZbkhRNjNHZUNYYyJ9.eyJhdWQiOiJodHRwczovL21hbmFnZW1lbnQuY29yZS53aW5kb3dzLm5ldC8iLCJpc3MiOiJodHRwczovL3N0cy53aW5kb3dzLm5ldC83MmY5ODhiZi04NmYxLTQxYWYtOTFhYi0yZDdjZDAxMWRiNDcvIiwiaWF0IjoxNTUzMDI2OTAyLCJuYmYiOjE1NTMwMjY5MDIsImV4cCI6MTU1MzAzMDgwMiwiX2NsYWltX25hbWVzIjp7Imdyb3VwcyI6InNyYzEifSwiX2NsYWltX3NvdXJjZXMiOnsic3JjMSI6eyJlbmRwb2ludCI6Imh0dHBzOi8vZ3JhcGgud2luZG93cy5uZXQvNzJmOTg4YmYtODZmMS00MWFmLTkxYWItMmQ3Y2QwMTFkYjQ3L3VzZXJzLzQ4NDA4ZWUxLTk4NGItNGUyNi1hZWM2LTcxMjU4ZWUzNTcyNS9nZXRNZW1iZXJPYmplY3RzIn19LCJhY3IiOiIxIiwiYWlvIjoiQVVRQXUvOEtBQUFBczNUWU9wWG81TlB2YjZicHNrY1gxVGVtakxCb1ByQm5KUWowUnIyZ2xUak4yT0pYYkZkaFVpVno2eklxcEZXOWxDRk96VGhyenY4TkRGUFREUEk1ZUE9PSIsImFtciI6WyJwd2QiLCJyc2EiLCJtZmEiXSwiYXBwaWQiOiIwNGIwNzc5NS04ZGRiLTQ2MWEtYmJlZS0wMmY5ZTFiZjdiNDYiLCJhcHBpZGFjciI6IjAiLCJkZXZpY2VpZCI6IjE5Yjk5ODlkLWVmY2EtNDYxYS05ZWUxLTZmMDRlMGUyNGEzMiIsImZhbWlseV9uYW1lIjoiWmh1IiwiZ2l2ZW5fbmFtZSI6IlhpYW95b25nIiwiaXBhZGRyIjoiMTMxLjEwNy4xNzQuMTY0IiwibmFtZSI6IlhpYW95b25nIFpodSIsIm9pZCI6IjQ4NDA4ZWUxLTk4NGItNGUyNi1hZWM2LTcxMjU4ZWUzNTcyNSIsIm9ucHJlbV9zaWQiOiJTLTEtNS0yMS0yMTI3NTIxMTg0LTE2MDQwMTI5MjAtMTg4NzkyNzUyNy0yNDQ1MDM1NCIsInB1aWQiOiIxMDAzMDAwMDg2MjUyMEE2Iiwic2NwIjoidXNlcl9pbXBlcnNvbmF0aW9uIiwic3ViIjoiRmIyV3BNOEpVTVdPVzVFWWVpb1FBOXBXNGl0NE1SaFpRMmFKS0xtRE9HdyIsInRpZCI6IjcyZjk4OGJmLTg2ZjEtNDFhZi05MWFiLTJkN2NkMDExZGI0NyIsInVuaXF1ZV9uYW1lIjoieGlhb3l6aHVAbWljcm9zb2Z0LmNvbSIsInVwbiI6InhpYW95emh1QG1pY3Jvc29mdC5jb20iLCJ1dGkiOiJJWDFaWHBQYW5FV1ZfRXo2TDZnREFBIiwidmVyIjoiMS4wIn0.f2jmS-inxahG9ny-cYBVT1Vv282J0pWA8MyKaFjl-Lcg3A6IMU1FPvdIH-DwkOD_Otbgnfb9uIeRdbz0-w2k2zKquBkFNZieLzuDYGJyC87Rm7JoSm_ArJT17ZUVNyO76IX2djZGjk2jNhC1OX1QN7G8H2TbMP-8SXr59voV6iYAygaOsR6Q1BVQlMqKnjHaZYRCwn3WlOquT1FF_Nf8Kaq1wSelRiSyZbsrv3Z-AdiNiPoz-UsvjeanLNLbnp2kHUxD50JxlGNZ9stoyefF_hSicMrKQa9WWrilq0jiOQUR-zGOi-2Cv7B4dMLB6MLlR6IPtHHcJHh-_g9aG_x2GQ'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aad_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor the new run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "HttpOperationError",
     "evalue": "Operation returned an invalid status code \"Exception of type 'Common.WebApi.Exceptions.ResourceNotFoundException' was thrown.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHttpOperationError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-017bce007400>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mazureml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPipelineRun\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpublished_pipeline_run\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPipelineRun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mws\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperiments\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"batch_scoring\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mRunDetails\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpublished_pipeline_run\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\azureml\\pipeline\\core\\run.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, experiment, run_id, _service_endpoint)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pipeline_run_provider\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mworkflow_provider\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipeline_run_provider\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;31m#######################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\azureml\\core\\run.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, experiment, run_id, outputs, **kwargs)\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[1;33m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m         \"\"\"\n\u001b[1;32m--> 107\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_dto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data_container_id\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\azureml\\_run_impl\\run_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, experiment, run_id, outputs, logs, _run_dto, _worker_pool, _user_agent, _ident, _batch_upload_metrics, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m                                         _parent_logger=self._logger, _batch_upload_metrics=_batch_upload_metrics)\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_internal_run_dto\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_run_dto\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m_run_dto\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;31m# self._run_dto property does some time-expensive serialization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\azureml\\_run_impl\\run_history_facade.py\u001b[0m in \u001b[0;36mget_run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m         \u001b[0mdto\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    136\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdto\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\azureml\\_restclient\\run_client.py\u001b[0m in \u001b[0;36mget_run\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[0mExperimentClient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0mspecific\u001b[0m \u001b[0mrun_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \"\"\"\n\u001b[1;32m---> 67\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRunClient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_token\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\azureml\\_restclient\\experiment_client.py\u001b[0m in \u001b[0;36mget_run\u001b[1;34m(self, run_id, caller, custom_headers, is_async)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         return self._execute_with_experiment_arguments(\n\u001b[1;32m--> 124\u001b[1;33m             self._client.run.get, run_id=run_id, **kwargs)\n\u001b[0m\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m     def get_runs(self, last=0, _filter_on_server=False,\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\azureml\\_restclient\\experiment_client.py\u001b[0m in \u001b[0;36m_execute_with_experiment_arguments\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    264\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_paginated_api\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 266\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_api\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_combine_with_experiment_paginated_dto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount_to_download\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\azureml\\_restclient\\clientbase.py\u001b[0m in \u001b[0;36m_call_api\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mAsyncTask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfuture\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_ident\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mident\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_parent_logger\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_logger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_execute_with_base_arguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_call_paginated_api\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\azureml\\_restclient\\clientbase.py\u001b[0m in \u001b[0;36m_execute_with_base_arguments\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mleft_retry\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    198\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mleft_retry\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\azureml\\_restclient\\operations\\run_operations.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, subscription_id, resource_group_name, workspace_name, experiment_name, run_id, custom_headers, raw, **operation_config)\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 303\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mHttpOperationError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_deserialize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    304\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m         \u001b[0mdeserialized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mHttpOperationError\u001b[0m: Operation returned an invalid status code \"Exception of type 'Common.WebApi.Exceptions.ResourceNotFoundException' was thrown.\""
     ]
    }
   ],
   "source": [
    "from azureml.pipeline.core.run import PipelineRun\n",
    "published_pipeline_run = PipelineRun(ws.experiments[\"batch_scoring\"], run_id)\n",
    "\n",
    "RunDetails(published_pipeline_run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "hichando"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
